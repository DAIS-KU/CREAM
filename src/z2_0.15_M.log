nohup: ignoring input
Running experiments: proposal_qq_low2
Start session: 0
End session: 10
Load cluster: False
Use cluster warming up: stream_seed
Use label: False
Use weight: False
Use tensor key: True
Use nbits: 12
Use max_iters: 3
Use warmingup_rate: None
Use warmingup_k: 12
Use cluster_min_size: 50
Use required_doc_size: 50
Use stream sampling rate: None
Use sampling size per query: 50
Number of Epochs: 1
Include answer: False
RandomProjectionLSH use_tensor_key True
Training Session 0/False
queries:2430, docs:60423
Read from: /home/work/retrieval/data/datasetM_large_share/train_session0_docs_filtered.jsonl
queries:2430, documents:31957
Using 1 GPUs: [device(type='cuda', index=0)]
RandomProjectionLSH use_tensor_key True
Query-Document encoding started.
Starting on cuda:0 with 2430 queries and 31957 documents (batch size 3072)
cuda:0 | Query encoding batch 0
new_q_data | new_q_data:2430, query_embeddings:2430
cuda:0 | Document encoding batch 0
cuda:0 | Document encoding batch 3072
cuda:0 | Document encoding batch 6144
cuda:0 | Document encoding batch 9216
cuda:0 | Document encoding batch 12288
cuda:0 | Document encoding batch 15360
cuda:0 | Document encoding batch 18432
cuda:0 | Document encoding batch 21504
cuda:0 | Document encoding batch 24576
cuda:0 | Document encoding batch 27648
cuda:0 | Document encoding batch 30720
new_d_data | new_d_data:31957, document_embeddings:31957
Query-Document encoding ended.(50.69700241088867 sec.)
query_list:2430, doc_list:31957
queries #2430, documents #34387 initial_docs #0
#doc_stream 34, stream_docs size 595-1024
Session 0 | Document count:34387
############################################Initialize(51.503724575042725sec)############################################
Load Warming up model.
RandomProjectionLSH use_tensor_key True
Initialize centroid
Starting iteration 1 | centroids: #12
cuda:0 | get_closest_clusters batch (0/8)
cuda:0 | get_closest_clusters batch (1/8)
cuda:0 | get_closest_clusters batch (2/8)
cuda:0 | get_closest_clusters batch (3/8)
cuda:0 | get_closest_clusters batch (4/8)
cuda:0 | get_closest_clusters batch (5/8)
cuda:0 | get_closest_clusters batch (6/8)
cuda:0 | get_closest_clusters batch (7/8)
clsuter 0 create new centroid.(instance 67)
clsuter 1 create new centroid.(instance 142)
clsuter 2 create new centroid.(instance 100)
clsuter 3 create new centroid.(instance 26)
clsuter 4 create new centroid.(instance 22)
clsuter 5 create new centroid.(instance 22)
clsuter 6 create new centroid.(instance 164)
clsuter 7 create new centroid.(instance 117)
clsuter 8 create new centroid.(instance 43)
clsuter 9 create new centroid.(instance 145)
clsuter 10 create new centroid.(instance 125)
clsuter 11 create new centroid.(instance 51)
iter_num 0 | execution_time: 9.996070384979248 sec.
cluster 0 size: 67
cluster 1 size: 142
cluster 2 size: 100
cluster 3 size: 26
cluster 4 size: 22
cluster 5 size: 22
cluster 6 size: 164
cluster 7 size: 117
cluster 8 size: 43
cluster 9 size: 145
cluster 10 size: 125
cluster 11 size: 51
centroids : 12
Create 0th Cluster.
Document only #63/67
Query only #4/67
update_statistics batch_token_embs:torch.Size([63, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
update_statistics batch_token_embs:torch.Size([4, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
Create 1th Cluster.
Document only #126/142
Query only #16/142
update_statistics batch_token_embs:torch.Size([126, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
update_statistics batch_token_embs:torch.Size([16, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
Create 2th Cluster.
Document only #97/100
Query only #3/100
update_statistics batch_token_embs:torch.Size([97, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
update_statistics batch_token_embs:torch.Size([3, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
Create 3th Cluster.
Document only #19/26
Query only #7/26
update_statistics batch_token_embs:torch.Size([19, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
update_statistics batch_token_embs:torch.Size([7, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
Create 4th Cluster.
Document only #22/22
Query only #0/22
update_statistics batch_token_embs:torch.Size([22, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
Create 5th Cluster.
Document only #20/22
Query only #2/22
update_statistics batch_token_embs:torch.Size([20, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
update_statistics batch_token_embs:torch.Size([2, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
Create 6th Cluster.
Document only #150/164
Query only #14/164
update_statistics batch_token_embs:torch.Size([128, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
update_statistics batch_token_embs:torch.Size([22, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
update_statistics batch_token_embs:torch.Size([14, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
Create 7th Cluster.
Document only #107/117
Query only #10/117
update_statistics batch_token_embs:torch.Size([107, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
update_statistics batch_token_embs:torch.Size([10, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
Create 8th Cluster.
Document only #43/43
Query only #0/43
update_statistics batch_token_embs:torch.Size([43, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
Create 9th Cluster.
Document only #136/145
Query only #9/145
update_statistics batch_token_embs:torch.Size([128, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
update_statistics batch_token_embs:torch.Size([8, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
update_statistics batch_token_embs:torch.Size([9, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
Create 10th Cluster.
Document only #103/125
Query only #22/125
update_statistics batch_token_embs:torch.Size([103, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
update_statistics batch_token_embs:torch.Size([22, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
Create 11th Cluster.
Document only #50/51
Query only #1/51
update_statistics batch_token_embs:torch.Size([50, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
update_statistics batch_token_embs:torch.Size([1, 254, 768]), self.prototype:torch.Size([1, 4096, 768])
Spend 10.489837408065796 seconds for clustering(12, 1024) warming up.
Assign 1th stream starts.
assign_instance_or_add_cluster started.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
assign_instance_or_add_cluster finished.(12)
Assign 1th stream ended(9.987915754318237sec).
Assign 2th stream starts.
assign_instance_or_add_cluster started.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
assign_instance_or_add_cluster finished.(12)
Assign 2th stream ended(9.972025394439697sec).
Assign 3th stream starts.
assign_instance_or_add_cluster started.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
assign_instance_or_add_cluster finished.(12)
Assign 3th stream ended(9.992789268493652sec).
Assign 4th stream starts.
assign_instance_or_add_cluster started.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
assign_instance_or_add_cluster finished.(12)
Assign 4th stream ended(10.19912052154541sec).
Assign 5th stream starts.
assign_instance_or_add_cluster started.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
assign_instance_or_add_cluster finished.(12)
Assign 5th stream ended(9.975540399551392sec).
Assign 6th stream starts.
assign_instance_or_add_cluster started.
ㄴ Batch 128 starts on cuda:0.
ㄴ Batch 128 starts on cuda:0.
